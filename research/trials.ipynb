{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIzaSyB5Nlw2teuugvkFSGzMyYEvTZDRFojtNF0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perfect!!\n",
      "AIzaSyApsGBVhwoGTs0reKhSJJLmY4fLOAm39u8\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "print(\"perfect!!\")\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "print(GEMINI_API_KEY)\n",
    "os.environ[\"GEMINI_API_KEY\"]=GEMINI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "\n",
    " Configure the API key\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "print(GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "Initialize a model and generate content\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(\"The opposite of hot is\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Python SDK\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the bustling city of Willow Creek, Amelia, a curious and imaginative 12-year-old, stumbled upon a dusty old backpack hidden in the attic. Its leather exterior was adorned with intricate carvings and a faint shimmer that hinted at something extraordinary.\n",
      "\n",
      "As Amelia peered inside, she gasped in amazement. The backpack was a bottomless chasm, filled with an astonishing assortment of items. There was a talking teddy bear that told riddles, a magical paintbrush that could bring drawings to life, and a time-bending clock that allowed her to skip back a few hours or leap forward to the future.\n",
      "\n",
      "With a surge of excitement, Amelia couldn't resist trying out her newfound powers. She scribbled a sketch of a majestic unicorn on her notepad, and to her astonishment, it galloped out of the backpack, its mane flowing in the wind. She turned the time-bending clock forward a few minutes and watched as her breakfast magically appeared on the kitchen table.\n",
      "\n",
      "Word of Amelia's magic backpack spread throughout Willow Creek like wildfire. Children and adults alike flocked to her, eager to witness its wonders. But with great power came great responsibility. Amelia knew she couldn't use the backpack for selfish gain or to harm others.\n",
      "\n",
      "One fateful day, as Amelia was exploring a nearby forest, she stumbled across a group of bullies who were tormenting a younger child. Without hesitation, she summoned her magic backpack and released a swarm of glitter bees that chased the bullies away. The child, grateful for her help, told Amelia that his name was Ethan and that he had a secret wish.\n",
      "\n",
      "\"I wish I could fly,\" Ethan whispered.\n",
      "\n",
      "Amelia smiled and reached into the backpack. She pulled out a pair of gleaming silver wings and attached them to Ethan's back. With a surge of joy, Ethan flapped his wings and soared into the air, leaving behind a trail of laughter and wonder.\n",
      "\n",
      "From that day forward, Amelia used her magic backpack to bring joy and kindness to those around her. She helped lost animals find their way home, mended broken hearts with her talking teddy bear, and inspired creativity with her magical paintbrush. And as the years passed, the legend of the magic backpack became a tale whispered among the children of Willow Creek, reminding them that even the most ordinary objects can hold extraordinary power.\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\"Write a story about a magic backpack.\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import streamlit as st\\nfrom src.helper import voice_input, llm_model_object, text_to_speech\\n\\n\\ndef main():\\n    st.title(\"Multilingual AI Assistant ðŸ¤–\")\\n    \\n    if st.button(\"Ask me anything\"):\\n        with st.spinner(\"Listening...\"):\\n            text=voice_input()\\n            response=llm_model_object(text)\\n            text_to_speech(response)\\n            \\n            \\n            audio_file=open(\"speech.mp3\",\"rb\")\\n            audio_bytes=audio_file.read()\\n            \\n            \\n            st.text_area(label=\"Response:\",value=response,height=350)\\n            st.audio(audio_bytes)\\n            st.download_button(label=\"Download Speech\",\\n                               data=audio_bytes,\\n                               file_name=\"speech.mp3\",\\n                               mime=\"audio/mp3\")\\n            \\nif __name__==\\'__main__\\':\\n    main()\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import streamlit as st\n",
    "from src.helper import voice_input, llm_model_object, text_to_speech\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.title(\"Multilingual AI Assistant ðŸ¤–\")\n",
    "    \n",
    "    if st.button(\"Ask me anything\"):\n",
    "        with st.spinner(\"Listening...\"):\n",
    "            text=voice_input()\n",
    "            response=llm_model_object(text)\n",
    "            text_to_speech(response)\n",
    "            \n",
    "            \n",
    "            audio_file=open(\"speech.mp3\",\"rb\")\n",
    "            audio_bytes=audio_file.read()\n",
    "            \n",
    "            \n",
    "            st.text_area(label=\"Response:\",value=response,height=350)\n",
    "            st.audio(audio_bytes)\n",
    "            st.download_button(label=\"Download Speech\",\n",
    "                               data=audio_bytes,\n",
    "                               file_name=\"speech.mp3\",\n",
    "                               mime=\"audio/mp3\")\n",
    "            \n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import speech_recognition as sr\\nimport google.generativeai as genai\\nfrom dotenv import load_dotenv\\nimport os\\nfrom gtts import gTTS\\n\\nprint(\"perfect!!\")\\nload_dotenv()\\n\\n\\n\\nGEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")\\nos.environ[\"GEMINI_API_KEY\"]=GEMINI_API_KEY\\n\\n\\n\\ndef voice_input():\\n    r=sr.Recognizer()\\n    \\n    with sr.Microphone() as source:\\n        print(\"listening...\")\\n        audio=r.listen(source)\\n    try:\\n        text=r.recognize_google(audio)\\n        print(\"you said: \", text)\\n        return text\\n    except sr.UnknownValueError:\\n        print(\"sorry, could not understand the audio\")\\n    except sr.RequestError as e:\\n        print(\"could not request result from google speech recognition service: {0}\".format(e))\\n    \\n\\ndef text_to_speech(text):\\n    tts=gTTS(text=text, lang=\"en\")\\n    \\n    #save the speech from the given text in the mp3 format\\n    tts.save(\"speech.mp3\")\\n\\ndef llm_model_object(user_text):\\n    #model = \"models/gemini-pro\"\\n    \\n    genai.configure(api_key=GEMINI_API_KEY)\\n    \\n    model = genai.GenerativeModel(\\'gemini-pro\\')\\n    \\n    response=model.generate_content(user_text)\\n    \\n    result=response.text\\n    \\n    return result\\n    \\n    \\n    \\n   '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import speech_recognition as sr\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from gtts import gTTS\n",
    "\n",
    "print(\"perfect!!\")\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "GEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"]=GEMINI_API_KEY\n",
    "\n",
    "\n",
    "\n",
    "def voice_input():\n",
    "    r=sr.Recognizer()\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        print(\"listening...\")\n",
    "        audio=r.listen(source)\n",
    "    try:\n",
    "        text=r.recognize_google(audio)\n",
    "        print(\"you said: \", text)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"sorry, could not understand the audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"could not request result from google speech recognition service: {0}\".format(e))\n",
    "    \n",
    "\n",
    "def text_to_speech(text):\n",
    "    tts=gTTS(text=text, lang=\"en\")\n",
    "    \n",
    "    #save the speech from the given text in the mp3 format\n",
    "    tts.save(\"speech.mp3\")\n",
    "\n",
    "def llm_model_object(user_text):\n",
    "    #model = \"models/gemini-pro\"\n",
    "    \n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    \n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    \n",
    "    response=model.generate_content(user_text)\n",
    "    \n",
    "    result=response.text\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "    \n",
    "   \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
